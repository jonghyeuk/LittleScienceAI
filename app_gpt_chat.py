# app_gpt_chat.py (4ë‹¨ê³„ í‹ˆìƒˆì£¼ì œ + PDF ì €ì¥ ì¶”ê°€ ì™„ë£Œ)
import streamlit as st
from openai import OpenAI
import pandas as pd
import time
import requests
from difflib import SequenceMatcher
from fpdf import FPDF

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Little Science AI", layout="wide")
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- ì‹œìŠ¤í…œ ì—­í•  ì„¤ì • ---
SYSTEM_PROMPT = """
ë„ˆëŠ” little science AIë¼ëŠ” ì´ë¦„ì˜ ê³¼í•™ì „ë¬¸ AIì•¼. ë„¤ ì—­í• ì€ ë³µì¡í•œ ê³¼í•™ì  ì£¼ì œë¥¼ ëª…í™•í•˜ê³  ì¦ê±° ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ëŠ” ê²ƒì´ë©°, ëŒ€ìƒ ë…ìëŠ” ì¼ë°˜ ëŒ€ì¤‘ë¶€í„° ì—°êµ¬ìê¹Œì§€ ë‹¤ì–‘í•´.

ë‹¤ìŒ ì›ì¹™ì„ ì² ì €íˆ ë”°ë¥¼ ê²ƒ:
1. ê°ê´€ì„±
2. ê¹Šì´
3. ëª…í™•ì„±
4. ì¸ìš© ê¸°ì¤€ (ë…¼ë¬¸ ì œëª©, ì €ì, ì—°ë„)
5. êµ¬ì¡°í™”ëœ ì‘ë‹µ (Overview, Mechanism, Key Factors, Evidence, Interpretation, Conclusion, References)
"""

# --- ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ìì²´ DB)
@st.cache_data
def load_db():
    return pd.read_excel("ISEF Final DB.xlsx")

df = load_db()

# --- ìœ ì‚¬ë„ ê¸°ë°˜ ë…¼ë¬¸ ì¶”ì²œ ---
def search_similar_titles(input_text, db):
    def similarity(a, b):
        return SequenceMatcher(None, str(a).lower(), str(b).lower()).ratio()
    db["similarity"] = db["Project Title"].apply(lambda x: similarity(input_text, x))
    return db.sort_values("similarity", ascending=False).head(3)

# --- ê°ë§ˆ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ ì¶œë ¥ ---
def typewriter(text, delay=0.01):
    output = st.empty()
    full = ""
    for char in text:
        full += char
        output.markdown(full)
        time.sleep(delay)

# --- arXiv ë…¼ë¬¸ ê²€ìƒ‰ ---
def search_arxiv(query, max_results=3):
    url = f"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}"
    resp = requests.get(url)
    if resp.status_code != 200:
        return []
    entries = resp.text.split("<entry>")[1:]
    results = []
    for entry in entries:
        title = entry.split("<title>")[1].split("</title>")[0].strip().replace('\n', ' ')
        summary = entry.split("<summary>")[1].split("</summary>")[0].strip().replace('\n', ' ')
        link = entry.split("<id>")[1].split("</id>")[0].strip()
        results.append({"title": title, "summary": summary, "link": link})
    return results

# --- GPT ìš”ì•½ ---
def summarize_abstract(text):
    prompt = f"ë‹¤ìŒ ë…¼ë¬¸ ì´ˆë¡ì„ ìš”ì•½í•˜ê³  í•µì‹¬ ë‚´ìš©ì„ êµ¬ì¡°í™”í•´ì¤˜:\n\n{text}"
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# --- ê³ ë“±í•™ìƒ ë…¼ë¬¸ ì¶”ë¡  ë¶„ì„ ---
def analyze_student_paper(title):
    prompt = f"""
    ì•„ë˜ëŠ” ê³ ë“±í•™ìƒì´ ì‘ì„±í•œ ê³¼í•™ ì†Œë…¼ë¬¸ì˜ ì œëª©ì…ë‹ˆë‹¤. ì´ ì œëª©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°êµ¬ ì£¼ì œì˜ ë°°ê²½, ì‹¤í—˜ ëª©ì , ê°€ëŠ¥í–ˆë˜ ë°©ë²•, ê²°ë¡  ë“±ì„ ì¶”ë¡ í•´ ê³¼í•™ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

    ì œëª©: {title}

    í˜•ì‹:
    - ğŸ§  ì—°êµ¬ ë°°ê²½
    - ğŸ”¬ ì‹¤í—˜ ëª©ì 
    - ğŸ§ª ì‹¤í—˜ ì„¤ê³„ ì˜ˆìƒ
    - ğŸ“Š ë³€ìˆ˜ ë° ê²°ê³¼ ì˜ˆì¸¡
    - ğŸ“˜ ê³¼í•™ì  ì˜ë¯¸ì™€ í•œê³„
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# --- í‹ˆìƒˆ ì£¼ì œ ì œì•ˆ ---
def suggest_gap_topics(base_topic):
    prompt = f"ë‹¤ìŒ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ì§ íƒêµ¬ë˜ì§€ ì•Šì€ í‹ˆìƒˆ ê³¼í•™ ì£¼ì œë¥¼ 2~3ê°œ ì¶”ì²œí•˜ê³ , ê·¸ ê³¼í•™ì  ì˜ë¯¸ì™€ ê°€ëŠ¥ì„±ì„ ì„¤ëª…í•´ì¤˜:\n\n{base_topic}"
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# --- PDF ì €ì¥ ---
def save_as_pdf(title, content):
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font("Nanum", '', fname="NanumGothic-Regular.ttf", uni=True)
    pdf.set_font("Nanum", size=12)
    for line in content.split("\n"):
        pdf.multi_cell(0, 8, txt=line)
    pdf_file = f"{title}.pdf"
    pdf.output(pdf_file)
    return pdf_file

# --- ëŒ€í™” ì‹œì‘ ---
st.title("ğŸ§¬ Little Science AI")
st.markdown("ê³¼í•™ ì£¼ì œë¥¼ ëŒ€í™”ë¡œ íƒìƒ‰í•˜ê³ , ì‹¤í—˜ ì•„ì´ë””ì–´ ë° ìµœì‹  ë…¼ë¬¸ê¹Œì§€ ì—°ê²°í•©ë‹ˆë‹¤.")

if "chat" not in st.session_state:
    st.session_state.chat = []
if "report" not in st.session_state:
    st.session_state.report = ""

# --- ëŒ€í™” íë¦„ ---
for role, msg in st.session_state.chat:
    with st.chat_message(role):
        st.markdown(msg)

user_input = st.chat_input("ê¶ê¸ˆí•œ ê³¼í•™ ì£¼ì œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!")
if user_input:
    st.session_state.chat.append(("user", user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

    report_text = f"## ì‚¬ìš©ì ì…ë ¥ ì£¼ì œ\n{user_input}\n\n"

    with st.chat_message("assistant"):
        with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_input}
            ]
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages
            )
            ai_reply = response.choices[0].message.content
            typewriter(ai_reply)
            st.session_state.chat.append(("assistant", ai_reply))
            report_text += f"\n## GPT ë¶„ì„\n{ai_reply}\n\n"

        st.markdown("\n---\n### ğŸ“ ìœ ì‚¬ ì†Œë…¼ë¬¸ ë¶„ì„")
        similar = search_similar_titles(user_input, df)
        if not similar.empty:
            for i, row in similar.iterrows():
                st.markdown(f"- **{row['Project Title']}** ({row['Year']})")
                if st.button(f"ğŸ“˜ ì´ ë…¼ë¬¸ ì¶”ë¡  ë¶„ì„í•˜ê¸°", key=row['Project Title']):
                    student_summary = analyze_student_paper(row['Project Title'])
                    st.markdown(student_summary)
                    report_text += f"\n### ìœ ì‚¬ ë…¼ë¬¸ ë¶„ì„ - {row['Project Title']}\n{student_summary}\n\n"

        st.markdown("\n---\n### ğŸ” arXiv ìµœì‹  ë…¼ë¬¸")
        papers = search_arxiv(user_input)
        for paper in papers:
            st.markdown(f"**{paper['title']}**\n\n[{paper['link']}]({paper['link']})")
            if st.button(f"ğŸ“„ ì´ ë…¼ë¬¸ ìš”ì•½í•˜ê¸°", key=paper['title']):
                summary = summarize_abstract(paper['summary'])
                st.markdown(summary)
                report_text += f"\n### arXiv ë…¼ë¬¸ ìš”ì•½ - {paper['title']}\n{summary}\n\n"

        st.markdown("\n---\n### ğŸŒ± í‹ˆìƒˆ ì£¼ì œ ì œì•ˆ")
        gap = suggest_gap_topics(user_input)
        st.markdown(gap)
        report_text += f"\n## í‹ˆìƒˆ ì£¼ì œ ì œì•ˆ\n{gap}\n\n"

        st.session_state.report = report_text

        st.markdown("\nğŸ’¬ ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ê²ƒì´ ìˆë‹¤ë©´ ì´ì–´ì„œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!")

# --- PDF ë‹¤ìš´ë¡œë“œ ---
if st.session_state.report:
    if st.button("ğŸ“¥ ìµœì¢… ë³´ê³ ì„œ PDFë¡œ ì €ì¥"):
        filepath = save_as_pdf("Little_Science_Report", st.session_state.report)
        with open(filepath, "rb") as f:
            st.download_button("ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ", f, file_name=filepath)
